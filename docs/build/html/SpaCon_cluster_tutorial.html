

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>load adata &mdash; SpaCon_tutorials 1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="_static/nbsphinx-code-cells.css?v=2aa19091" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=f2a433a1"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
      <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="SpaCon_tutorials documentation" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            SpaCon_tutorials
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">教程列表</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">load adata</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">SpaCon_tutorials</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">load adata</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/SpaCon_cluster_tutorial.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import sys
sys.path.append(&quot;/mnt/Data16Tc/home/haichao/code/SpaCon/&quot;)
from scipy.sparse import coo_matrix, save_npz, load_npz
from model.utils import build_spatial_graph, build_connection_graph

from model.Model_Pyg_SpaCon import SpaCon
# from model.r_mcluster import mclust_R
from torch_geometric.loader import NeighborLoader
from model.Similar_Neightbor_Loader import similar_neighbor_loder

import torch.nn.functional as F
import copy
import datetime
import os
import scanpy as sc
import pandas as pd
import matplotlib.pyplot as plt

import torch
import numpy as np
from tqdm import tqdm
import pickle

import warnings
warnings.filterwarnings(&quot;ignore&quot;)

mus = &#39;mouse_1&#39;
if mus == &#39;mouse_1&#39;:
    plot_x, plot_y = &#39;z&#39;, &#39;y&#39;
    figsize1 = (5,5)
    figsize2 = (4,5)
elif mus == &#39;mouse_3&#39;:
    plot_x, plot_y = &#39;x&#39;, &#39;y&#39;
    figsize1 = (11,5)
    figsize2 = (9,5)
</pre></div>
</div>
</div>
<section id="load-adata">
<h1>load adata<a class="headerlink" href="#load-adata" title="Link to this heading"></a></h1>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>adata = sc.read_h5ad(f&#39;./data/{mus}/adata_merge.h5ad&#39;)
print(&#39;raw adata shape:&#39;, adata.shape)
sc.pp.normalize_total(adata, target_sum=1e4)
sc.pp.log1p(adata)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># build the section list
section_order = np.unique(adata.obs[&#39;section&#39;]).tolist()
# calculate the spatial graph for the adata
ST_graph_data, st_adj = build_spatial_graph(adata=adata,  rad_cutoff=0.7, rad_cutoff_Zaxis=1.0,
                                            sec_x=&#39;x&#39;, sec_y=&#39;y&#39;, key_section=&#39;section&#39;,
                                            section_order=section_order)
ST_graph_data
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>nt_adj = np.load(&#39;/mnt/Data18Td/Data/haichao/mouse_connect_data/NT/zxw/mouse_1/zxw_adj.npy&#39;)
NT_graph_data = build_connection_graph(adata, nt_adj, threshold=0.001)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>sampling_method = &#39;neighbor_loader&#39;   # neighbor_loader or similar_neighbor_loder, For particularly large datasets, using similar_neighbor_loder may consume more memory.

if sampling_method == &#39;neighbor_loader&#39;:
    train_loader = NeighborLoader(NT_graph_data, shuffle=False, num_neighbors=[20, 10, 10],
                                  batch_size=32, num_workers=4)
elif sampling_method == &#39;similar_neighbor_loder&#39;:
    # correlation between points
    expression_matrix = adata.X.A
    correlation_matrix = np.corrcoef(expression_matrix)
    np.fill_diagonal(correlation_matrix, 0)
    # train loader
    train_loader = similar_neighbor_loder(NT_graph_data, correlation_matrix, batch_size=32, num_neighbors=[20, 10, 10], beta=0.1)

# evaluate loader
evaluate_loader_con = NeighborLoader(copy.copy(NT_graph_data), input_nodes=None, shuffle=False, num_neighbors=[-1], batch_size=32, num_workers=4)   # test_loader: num_neighbors=[-1]
# Add global node index information.
evaluate_loader_con.data.num_nodes = NT_graph_data.num_nodes
evaluate_loader_con.data.n_id = torch.arange(NT_graph_data.num_nodes)

# evaluate
evaluate_loader_spa = NeighborLoader(copy.copy(ST_graph_data), input_nodes=None, shuffle=False, num_neighbors=[-1], batch_size=32, num_workers=4)   # test_loader: num_neighbors=[-1]
# Add global node index information.
evaluate_loader_spa.data.num_nodes = ST_graph_data.num_nodes
evaluate_loader_spa.data.n_id = torch.arange(ST_graph_data.num_nodes)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>device = torch.device(&#39;cuda:0&#39; if torch.cuda.is_available() else &#39;cpu&#39;)

# hyper-parameters
num_epoch = 4
lr = 0.0001
weight_decay = 1e-4
hidden_dims = [adata.X.shape[1]] + [256, 64, 16]
# model
model = SpaCon(hidden_dims=hidden_dims, fusion_method=&#39;concat&#39;).to(device)

loss_list = []
# for training
optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)
model.train()
for epoch in range(1, num_epoch+1):
    loss_batch = 0
    print(f&#39;epoch:{epoch}|{num_epoch}&#39;)
    for batch_NT in tqdm(train_loader):
        # model.train()
        optimizer.zero_grad()
        batch_NT = batch_NT.to(device)
        n_id = batch_NT.n_id.to(&#39;cpu&#39;).detach().numpy()
        st_adj_batch = st_adj[n_id][:, n_id]
        edgeList = np.argwhere(st_adj_batch)
        f_con, f_spa, re = model(batch_NT.x, batch_NT.edge_index, torch.LongTensor(edgeList.T).to(device))
        loss = F.mse_loss(batch_NT.x, re, reduction=&quot;sum&quot;)
        loss_batch += loss.to(&#39;cpu&#39;).detach().numpy()
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.)
        optimizer.step()
        # break
    loss_list.append(loss_batch)
plt.plot(range(1, len(loss_list) + 1), loss_list, marker=&#39;o&#39;, linestyle=&#39;-&#39;)
plt.grid(True)
plt.show()

path = f&quot;./results_gate_skip_connect/{mus}/&quot;+str(datetime.datetime.now().strftime(&#39;%Y_%m_%d_%H_%M_%S&#39;)+f&#39;GATE_2encoder_cat_feature_decoder_skip_connect_bn/&#39;)
os.makedirs(path)
print(path)
torch.save(model.state_dict(), path+&#39;/model_params.pth&#39;)
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
epoch:1|4
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
100%|██████████| 7830/7830 [10:38&lt;00:00, 12.27it/s]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
606717963705.6094
epoch:2|4
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
100%|██████████| 7830/7830 [11:03&lt;00:00, 11.80it/s]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
369082052682.2656
epoch:3|4
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
100%|██████████| 7830/7830 [11:11&lt;00:00, 11.67it/s]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
308715753823.5078
epoch:4|4
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
100%|██████████| 7830/7830 [10:03&lt;00:00, 12.97it/s]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
288194521107.8672
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/SpaCon_cluster_tutorial_6_9.png" src="_images/SpaCon_cluster_tutorial_6_9.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
./results_gate_skip_connect/mouse_1/2024_08_13_11_20_51GATE_2encoder_cat_feature_decoder_skip_connect_bn/
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># model evaluate
layer_eval = True

model.eval()
if layer_eval == True:
    feature_con = model.con_inference(NT_graph_data.x, evaluate_loader_con, device=device)
    feature_spa = model.spa_inference(ST_graph_data.x, evaluate_loader_spa, device=device)
    adata.obsm[&#39;feature_spa&#39;] = feature_spa.to(&#39;cpu&#39;).detach().numpy()
    adata.obsm[&#39;feature_con&#39;] = feature_con.to(&#39;cpu&#39;).detach().numpy()
# all data evaluate
else:
    f_con_list = []
    f_spa_list = []
    re_list = []
    for batch_NT in tqdm(evaluate_loader_con):
        batch_NT = batch_NT.to(device)
        n_id = batch_NT.n_id.to(&#39;cpu&#39;).detach().numpy()
        st_adj_batch = st_adj[n_id][:, n_id]
        edgeList = np.argwhere(st_adj_batch)
        f_con, f_spa, re = model(batch_NT.x, batch_NT.edge_index, torch.LongTensor(edgeList.T).to(device))

        f_con_list.append(f_con[:batch_NT.batch_size].to(&#39;cpu&#39;).detach().numpy())
        f_spa_list.append(f_spa[:batch_NT.batch_size].to(&#39;cpu&#39;).detach().numpy())
        re_list.append(re[:batch_NT.batch_size].to(&#39;cpu&#39;).detach().numpy())

    f_con = np.concatenate(f_con_list, axis=0)
    f_spa = np.concatenate(f_spa_list, axis=0)
    re = np.concatenate(re_list, axis=0)
    adata.obsm[&#39;feature_spa&#39;] =f_spa
    adata.obsm[&#39;feature_con&#39;] =f_con
    adata.layers[&#39;exp_reconstructed&#39;] = re
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Evaluating: 100%|██████████| 751605/751605 [08:44&lt;00:00, 1432.71it/s]
Evaluating: 100%|██████████| 751605/751605 [01:10&lt;00:00, 10647.52it/s]
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.preprocessing import MinMaxScaler, StandardScaler
scaler_standard = StandardScaler()
f_con = scaler_standard.fit_transform(adata.obsm[&#39;feature_con&#39;])
f_spa = scaler_standard.fit_transform(adata.obsm[&#39;feature_spa&#39;])
alp=0
f_alp = (np.exp(-4 * alp) - 1) / (np.exp(-4) - 1)
f_add = f_alp*f_con + (1-f_alp)*f_spa
adata.obsm[&#39;feature_add&#39;] = f_add

sc.pp.neighbors(adata, use_rep=&#39;feature_add&#39;, n_neighbors=40)
sc.tl.umap(adata)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>resolution = 0.75
fig_path = path + f&#39;feature_add_weight{alp}/Clusters_res{resolution}/&#39;
os.makedirs(fig_path, exist_ok=True)

sc.tl.louvain(adata,
             resolution=resolution,   # default=1  resolution = k*num (k&gt;0)
             key_added=&quot;clusters&quot;)
sc.pl.umap(adata,color=&#39;clusters&#39;, show=False)
plt.tight_layout()
plt.savefig(fig_path+f&#39;umap_res{resolution}.png&#39;)
adata.write_h5ad(fig_path+&#39;/adata_cluster_feature.h5ad&#39;)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/SpaCon_cluster_tutorial_9_0.png" src="_images/SpaCon_cluster_tutorial_9_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>for it, label in enumerate(np.unique(adata.obs[&#39;section&#39;])):
    temp_adata = adata[adata.obs[&#39;section&#39;] == label, ]
    fig = plt.figure(figsize=figsize1)
    plt.scatter(temp_adata.obs[plot_x].values, temp_adata.obs[plot_y].values, c=temp_adata.obs[&#39;clusters&#39;].astype(&#39;int&#39;).values, cmap=&#39;Spectral_r&#39;, s=10)  # viridis 绘制样本点
    plt.gca().invert_yaxis()
    plt.colorbar()
    plt.savefig(fig_path + &#39;/section_&#39;+str(label)+&#39;.png&#39;)
    plt.close()

for Class_i in tqdm(range(np.unique(np.array(adata.obs[&#39;clusters&#39;])).shape[0])):  # adata.shape[0]
    # build the spot_i anndata
    Class_i_adata = adata[adata.obs[&#39;clusters&#39;]==str(Class_i)]
    # build the save path
    fig_eachclass_path = fig_path+&#39;/cluster_result_eachclass/ClassNum_&#39;+str(Class_i)+&#39;_sameclasssSpotsNum_&#39;+str(Class_i_adata.shape[0])
    if os.path.exists(fig_eachclass_path) == False:
        os.makedirs(fig_eachclass_path)  # build all the folders
    # plot same class as the spoti on every section
    for label in set(Class_i_adata.obs[&#39;section&#39;].values):
        adata_section = adata[adata.obs[&#39;section&#39;] == label]
        adata_class = Class_i_adata[Class_i_adata.obs[&#39;section&#39;] == label]

        fig = plt.figure(figsize=figsize2)
        # plot
        plt.scatter(adata_section.obs[plot_x].values, adata_section.obs[plot_y].values, c=&#39;#D3D3D3&#39;, s=10)
        plt.scatter(adata_class.obs[plot_x].values, adata_class.obs[plot_y].values, c=&#39;#FF6347&#39;, s=10)
        plt.gca().invert_yaxis()
        # plt.legend(loc=&#39;upper right&#39;, prop={&#39;size&#39;:5})
        plt.savefig(fig_eachclass_path + &#39;/section_&#39;+str(label)+&#39;.png&#39;)
        # plt.show()
        plt.close()
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
100%|██████████| 24/24 [02:36&lt;00:00,  6.50s/it]
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="SpaCon_tutorials documentation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, quhaichao.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>